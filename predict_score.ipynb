{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**VALENCE SCORE PREDICTOR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXUU8k9SdLFK",
        "outputId": "5b2b36a9-9b1b-40c1-8f73-1bc02c24644d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import string\n",
        "\n",
        "file_path = '/Data.txt' # Path to the file containing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8P9-4TidWFi"
      },
      "outputs": [],
      "source": [
        "### 1. Load Data from File ###\n",
        "def load_dataset(filename):\n",
        "    dataset = [] # Create an empty list to store the data\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file: \n",
        "        for line in file:\n",
        "            parts = line.strip().rsplit(\"\\t\", 1)  # Split by last space\n",
        "            if len(parts) == 2: \n",
        "                word, score = parts # Assign the word and score to the variables\n",
        "                try:\n",
        "                    score = float(score) # Convert the score to a float\n",
        "                    dataset.append((word.lower(), score)) # Append the word and score to the dataset\n",
        "                except ValueError:\n",
        "                    print(\"Error\") # Print an error message if the line is not in the correct format\n",
        "                    print(line)\n",
        "                    break\n",
        "    return dataset\n",
        "\n",
        "dataset = load_dataset(\"Data.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zY9jmwTTdnbS"
      },
      "outputs": [],
      "source": [
        "### 2. Character Encoding ###\n",
        "chars = string.ascii_lowercase  # 26 lowercase letters\n",
        "char_to_idx = {char: i for i, char in enumerate(chars)} # Create a dictionary with the index of each character\n",
        "idx_to_char = {i: char for char, i in char_to_idx.items()}\n",
        "\n",
        "def encode_word(word): \n",
        "    encoded = torch.zeros(len(word), input_size, dtype=torch.float) # Create a tensor of zeros with the length of the word\n",
        "    for i, char in enumerate(word): # Loop through each character in the word\n",
        "        if char in char_to_idx: # Check if the character is in the dictionary\n",
        "            encoded[i, char_to_idx[char]] = 1 # Set the value of the character to 1\n",
        "    return encoded.unsqueeze(0)\n",
        "\n",
        "# No need for decoding, as the output will be a numeral (score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvIH7Xf2dsaa"
      },
      "outputs": [],
      "source": [
        "### 3. Define Character-Level Sentiment Model ###\n",
        "class CharRNN(nn.Module): # Create a class for the model\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1): # Define the initialisation function\n",
        "        super(CharRNN, self).__init__() \n",
        "        self.hidden_size = hidden_size # Size of the hidden layer\n",
        "        self.n_layers = n_layers # Number of layers in the model (set to default, 1)\n",
        "\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, n_layers, batch_first=True) # Define the LSTM layer\n",
        "        self.fc = nn.Linear(hidden_size, output_size) # Define the linear layer\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        out, hidden = self.rnn(x, hidden) # Pass the input and hidden state through the LSTM layer\n",
        "        out = self.fc(out[:, -1, :])  # Take last output for prediction\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size): # Initialise the hidden state\n",
        "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size),\n",
        "                torch.zeros(self.n_layers, batch_size, self.hidden_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v7W50LsgASY"
      },
      "outputs": [],
      "source": [
        "### 4. Training setup ###\n",
        "input_size = len(chars)  # 26 (one-hot for each character)\n",
        "hidden_size = 128 # Number of hidden units in the LSTM layer\n",
        "output_size = 1  # Predict sentiment score\n",
        "\n",
        "model = CharRNN(input_size, hidden_size, output_size) # Create an instance of the model\n",
        "criterion = nn.MSELoss() # Define the loss function (MSELoss)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001) # Define the optimizer (Adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiJeUEhngHGo",
        "outputId": "e3c71ce0-3b7b-4b49-c35b-7b49820ce6ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 19769.1251\n",
            "Epoch 10, Loss: 16342.0889\n",
            "Epoch 20, Loss: 4963.1839\n",
            "Epoch 30, Loss: 1645.8936\n",
            "Epoch 40, Loss: 844.8128\n",
            "Epoch 50, Loss: 528.3331\n",
            "Epoch 60, Loss: 412.0173\n",
            "Epoch 70, Loss: 371.6645\n",
            "Epoch 80, Loss: 285.2679\n",
            "Epoch 90, Loss: 259.2511\n"
          ]
        }
      ],
      "source": [
        "## Training loop\n",
        "for epoch in range(100): # Loop through 100 epochs\n",
        "    total_loss = 0 # Set the total loss to 0\n",
        "    for word, score in dataset: # Loop through each word and score in the dataset\n",
        "        encoded = encode_word(word).float()  # Convert to tensor\n",
        "        hidden = (torch.zeros(model.n_layers, 1, model.hidden_size), # Initialise hidden state\n",
        "                  torch.zeros(model.n_layers, 1, model.hidden_size))\n",
        "\n",
        "        output, _ = model(encoded, hidden) # Pass the input and hidden state through the model\n",
        "        loss = criterion(output, torch.tensor([[score]])) # Calculate the loss\n",
        "\n",
        "        optimizer.zero_grad() \n",
        "        loss.backward() \n",
        "        optimizer.step()  # Update the weights\n",
        "\n",
        "        total_loss += loss.item() \n",
        "\n",
        "    if epoch % 10 == 0: # Print the epoch and loss every 10\n",
        "        print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hFbtF4ugdI3",
        "outputId": "3df25124-cd0f-48d6-c80d-d3322c854569"
      },
      "outputs": [],
      "source": [
        "### 5. Predict the valence score ###\n",
        "def predict(word): # Define a function to predict the valence score\n",
        "    model.eval() # Set the model to evaluation mode\n",
        "    encoded = encode_word(word).float() # Encode the word\n",
        "    hidden = model.init_hidden(1) # Initialise the hidden state\n",
        "    output, _ = model(encoded, hidden) # Pass the input and hidden state through the model\n",
        "    return output.item() # Return the output as a float (the valence score)\n",
        "\n",
        "prediction_word = \"test\" # Word to predict the valence score for!!\n",
        "print(f\"Score for ({prediction_word}):\", predict(prediction_word))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
